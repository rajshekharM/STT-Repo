{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final Copy of Testing_Pipeline_3epoch.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJyidWtD-lVy",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# imports pytorch\n",
        "import json\n",
        "import re\n",
        "import torch\n",
        "# imports the torch_xla package\n",
        "# import torch_xla\n",
        "# import torch_xla.core.xla_model as xm\n",
        "# import torch_xla.distributed.xla_multiprocessing as xmp\n",
        "# install\n",
        "!pip install pytorch-pretrained-bert pytorch-nlp\n",
        "import torchvision\n",
        "from torchvision import datasets\n",
        "import torchvision.transforms as transforms\n",
        "# import parallel loader\n",
        "# import torch_xla.distributed.parallel_loader as pl\n",
        "import time\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler, DistributedSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "from pytorch_pretrained_bert import BertTokenizer, BertConfig\n",
        "from pytorch_pretrained_bert import BertAdam, BertForSequenceClassification, BertForQuestionAnswering\n",
        "from tqdm import tqdm, trange\n",
        "import pandas as pd\n",
        "import io\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ruKZgTMLq4ms",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from scipy.special import softmax"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SlwbWYtm5Lc2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import selection binary models\n",
        "selection_model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
        "# load test model parameters\n",
        "selection_path = F\"/content/drive/My Drive/HydraNet/RetrainModels/SelectionClause/retrain_selectionclause_classifier_epoch_3.pt\"\n",
        "selection_model.load_state_dict(torch.load(selection_path))\n",
        "# selection_model.to(test_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sjW3gYc4VMf4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import aggregation mullti-class models\n",
        "aggregation_model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=6)\n",
        "# load test model parameters\n",
        "aggregation_path = F\"/content/drive/My Drive/HydraNet/RetrainModels/AggregationOperator/retrain_aggregation_operator_classifier_epoch_3.pt\"\n",
        "aggregation_model.load_state_dict(torch.load(aggregation_path))\n",
        "# aggregation_model.to(test_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "83Ud5dVbs-r7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import wherenum mullti-class models\n",
        "wherenum_model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=5)\n",
        "# load test model parameters\n",
        "wherenum_path = F\"/content/drive/My Drive/HydraNet/RetrainModels/NumWhereConditions/retrain_wherenum_classifier_epoch_3.pt\"\n",
        "wherenum_model.load_state_dict(torch.load(wherenum_path))\n",
        "# wherenum_model.to(test_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JwAksf7Nxldb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import isin_relevance binary models\n",
        "isinrelevance_model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
        "# load test model parameters\n",
        "isinrelevance_path = F\"/content/drive/My Drive/HydraNet/RetrainModels/IsInRelevanceClause/retrain_isinrelevanceclause_classifier_epoch_3.pt\"\n",
        "isinrelevance_model.load_state_dict(torch.load(isinrelevance_path))\n",
        "# isinrelevance_model.to(test_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2DAg8x_yqSI",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import isin_where binary models\n",
        "isinwhere_model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=2)\n",
        "# load test model parameters\n",
        "isinwhere_path = F\"/content/drive/My Drive/HydraNet/RetrainModels/IsInWhereClause/retrain_isinwhereclause_classifier_epoch_3.pt\"\n",
        "isinwhere_model.load_state_dict(torch.load(isinwhere_path))\n",
        "# isinwhere_model.to(test_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nJXNn91L8NVw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import where operator multi-class models\n",
        "whereoperator_model = BertForSequenceClassification.from_pretrained(\"bert-large-uncased\", num_labels=3)\n",
        "# load test model parameters\n",
        "whereoperator_path = F\"/content/drive/My Drive/HydraNet/RetrainModels/ConditionOperator/retrain_condition_operator_classifier_epoch_3.pt\"\n",
        "whereoperator_model.load_state_dict(torch.load(whereoperator_path))\n",
        "# whereoperator_model.to(test_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yq64dAfjFFCl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# import where value question-answering models\n",
        "wherevalue_model = BertForQuestionAnswering.from_pretrained(\"bert-large-uncased\")\n",
        "# load test model parameters\n",
        "wherevalue_path = F\"/content/drive/My Drive/HydraNet/RetrainModels/WhereValue/retrain_where_value_model_epoch_3.pt\"\n",
        "wherevalue_model.load_state_dict(torch.load(wherevalue_path))\n",
        "# wherevalue_model.to(test_device)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "50fHdaoBihtT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input questions and table headers as well as table type\n",
        "input_question = 'what is the total revenue for apple in canada when the profit is more than 300'\n",
        "input_columns = ['Region', 'Fruit', 'Amount (kilo) weight', 'Salesperson', 'Customer Type', 'Revenue (dollar)', 'Profit (dollar)']\n",
        "input_types = ['text', 'text', 'real', 'text', 'text', 'real', 'real']\n",
        "MAX_LEN = 64\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "aggregation_operator_list = [\"NAN\", \"max\", \"min\", \"nunique\", \"sum\", \"mean\"]\n",
        "condition_operator_list = [\"=\", \">\", \"<\"]\n",
        "table_name = 'Fruits'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BpYXf_N8MX16",
        "colab_type": "text"
      },
      "source": [
        "Form the [CLS] + type + column + [SEP] + question + [SEP] input"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MjpRVy-F-C8r",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prepare_input(question, columns, types, max_len, bert_tokenizer):\n",
        "  list_of_str = []\n",
        "  for i in range(len(columns)):\n",
        "    input_str = '[CLS] ' + str(types[i]) + ' ' + str(columns[i]) + ' [SEP] ' + str(question) + ' [SEP]'\n",
        "    list_of_str.append(input_str)\n",
        "  test_tokenized = [bert_tokenizer.tokenize(sentence) for sentence in list_of_str]\n",
        "  test_input_ids = [bert_tokenizer.convert_tokens_to_ids(x) for x in test_tokenized]\n",
        "  test_input_ids = pad_sequences(test_input_ids, maxlen=max_len, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "  test_attention_masks = []\n",
        "  test_segment_ids = []\n",
        "  for seq in test_input_ids:\n",
        "    seq_mask = [float(i > 0) for i in seq]\n",
        "    test_attention_masks.append(seq_mask)\n",
        "    seq_segment = [0] * len(seq)\n",
        "    seq_np = np.array(seq)\n",
        "    temp = np.nonzero(seq_np == 102)\n",
        "    if len(temp) > 0:\n",
        "      if len(temp[0]) > 0:\n",
        "        index = temp[0][0]\n",
        "        seq_segment[index+1:] = [1] * (len(seq) - (index + 1))\n",
        "    test_segment_ids.append(seq_segment)\n",
        "  return test_tokenized, test_input_ids, test_attention_masks, test_segment_ids "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5i41Tbd-MqsR",
        "colab_type": "text"
      },
      "source": [
        "Prediction Selection Clause. Give the input columns list, ['Region', 'Fruit', 'Amount Sold', 'Salesperson', 'Customer Type', 'Revenue', 'Profit'], find the index of selection column in the columns list"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VtmzXBEw4LJw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_selection_clause(selection_model, test_input_ids, test_attention_masks, test_segment_ids):\n",
        "  # put the tensors into tpu\n",
        "  # selection_model.to(test_device)\n",
        "  test_input_ids = torch.tensor(test_input_ids)\n",
        "  test_attention_masks = torch.tensor(test_attention_masks)\n",
        "  test_segment_ids = torch.tensor(test_segment_ids)\n",
        "  test_input_ids_tpu = test_input_ids\n",
        "  test_attention_masks_tpu = test_attention_masks\n",
        "  test_segment_ids_tpu = test_segment_ids\n",
        "  selection_model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = selection_model(input_ids=test_input_ids_tpu, token_type_ids=test_segment_ids_tpu, attention_mask=test_attention_masks_tpu)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  sigmoid_logits = [1/(1+np.exp(-1 * each_logit)) for each_logit in logits]\n",
        "  sigmoid_logits_1 = []\n",
        "  for each_row in sigmoid_logits:\n",
        "    # only care about the class that labels as 1\n",
        "    sigmoid_logits_1.append(each_row[1])\n",
        "  max_index = np.argmax(sigmoid_logits_1)\n",
        "  return max_index, sigmoid_logits_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t3YPr8MHb5jv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_aggregation_operator(aggregation_model, test_input_ids, test_attention_masks, test_segment_ids):\n",
        "  # aggregation_model.to(test_device)\n",
        "  test_input_ids_agg = [test_input_ids]\n",
        "  test_input_ids_agg = torch.tensor(test_input_ids_agg)\n",
        "  test_input_ids_agg_tpu = test_input_ids_agg\n",
        "  test_attention_masks_agg = [test_attention_masks]\n",
        "  test_attention_masks_agg = torch.tensor(test_attention_masks_agg)\n",
        "  test_attention_masks_agg_tpu = test_attention_masks_agg\n",
        "  test_segment_ids_agg = [test_segment_ids]\n",
        "  test_segment_ids_agg = torch.tensor(test_segment_ids_agg)\n",
        "  test_segment_ids_agg_tpu = test_segment_ids_agg\n",
        "  aggregation_model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = aggregation_model(input_ids=test_input_ids_agg_tpu, token_type_ids=test_segment_ids_agg_tpu, attention_mask=test_attention_masks_agg_tpu)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  sigmoid_logits = [1/(1+np.exp(-1 * each_logit)) for each_logit in logits]\n",
        "  max_index = np.argmax(sigmoid_logits[0])\n",
        "  return max_index, sigmoid_logits[0]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "giuRPigEOwht",
        "colab_type": "text"
      },
      "source": [
        "The following two functions predict the num of where clauses"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HfEb5ZChs6q5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_wherenum(wherenum_model, test_input_ids, test_attention_masks, test_segment_ids):\n",
        "  # put the tensors into tpu\n",
        "  # wherenum_model.to(test_device)\n",
        "  test_input_ids = torch.tensor(test_input_ids)\n",
        "  test_attention_masks = torch.tensor(test_attention_masks)\n",
        "  test_segment_ids = torch.tensor(test_segment_ids)\n",
        "  test_input_ids_tpu = test_input_ids\n",
        "  test_attention_masks_tpu = test_attention_masks\n",
        "  test_segment_ids_tpu = test_segment_ids\n",
        "  wherenum_model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = wherenum_model(input_ids=test_input_ids_tpu, token_type_ids=test_segment_ids_tpu, attention_mask=test_attention_masks_tpu)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  return logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kQ4Bo9O_0SU4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_isinrelevance(isinrelevance_model, test_input_ids, test_attention_masks, test_segment_ids):\n",
        "  # put the tensors into tpu\n",
        "  # isinrelevance_model.to(test_device)\n",
        "  test_input_ids = torch.tensor(test_input_ids)\n",
        "  test_attention_masks = torch.tensor(test_attention_masks)\n",
        "  test_segment_ids = torch.tensor(test_segment_ids)\n",
        "  test_input_ids_tpu = test_input_ids\n",
        "  test_attention_masks_tpu = test_attention_masks\n",
        "  test_segment_ids_tpu = test_segment_ids\n",
        "  isinrelevance_model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = isinrelevance_model(input_ids=test_input_ids_tpu, token_type_ids=test_segment_ids_tpu, attention_mask=test_attention_masks_tpu)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  sigmoid_logits = [1/(1+np.exp(-1 * each_logit)) for each_logit in logits]\n",
        "  sigmoid_logits_1 = []\n",
        "  for each_row in sigmoid_logits:\n",
        "    # only care about the class that labels as 1\n",
        "    sigmoid_logits_1.append(each_row[1])\n",
        "  return sigmoid_logits_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zbQGhBIQOnyA",
        "colab_type": "text"
      },
      "source": [
        "Predict if a column is in where clause"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hp4-R_U54RXV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_isinwhere(isinwhere_model, test_input_ids, test_attention_masks, test_segment_ids):\n",
        "  # put the tensors into tpu\n",
        "  # isinwhere_model.to(test_device)\n",
        "  test_input_ids = torch.tensor(test_input_ids)\n",
        "  test_attention_masks = torch.tensor(test_attention_masks)\n",
        "  test_segment_ids = torch.tensor(test_segment_ids)\n",
        "  test_input_ids_tpu = test_input_ids\n",
        "  test_attention_masks_tpu = test_attention_masks\n",
        "  test_segment_ids_tpu = test_segment_ids\n",
        "  isinwhere_model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = isinwhere_model(input_ids=test_input_ids_tpu, token_type_ids=test_segment_ids_tpu, attention_mask=test_attention_masks_tpu)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  sigmoid_logits = [1/(1+np.exp(-1 * each_logit)) for each_logit in logits]\n",
        "  sigmoid_logits_1 = []\n",
        "  for each_row in sigmoid_logits:\n",
        "    # only care about the class that labels as 1\n",
        "    sigmoid_logits_1.append(each_row[1])\n",
        "  return sigmoid_logits_1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8FbvnRs15RP6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_wherecolumns(probability, numwhere):\n",
        "  array_probability = np.array(probability)\n",
        "  return array_probability.argsort()[-numwhere:][::-1]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aaf12jBOGrB",
        "colab_type": "text"
      },
      "source": [
        "Given the where condition list, ['=', '>', '<', 'OP'], find the condition operator index for where columns. (Ignore 'OP', because no questions have 'OP' as the condition operator for WIKISQL)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XwJFwZISBgdf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_where_operator(whereoperator_model, test_input_ids, test_attention_masks, test_segment_ids):\n",
        "  # whereoperator_model.to(test_device)\n",
        "  test_input_ids_whereoperator = test_input_ids\n",
        "  test_input_ids_whereoperator = torch.tensor(test_input_ids_whereoperator)\n",
        "  test_input_ids_whereoperator_tpu = test_input_ids_whereoperator\n",
        "  test_attention_masks_whereoperator = test_attention_masks\n",
        "  test_attention_masks_whereoperator = torch.tensor(test_attention_masks_whereoperator)\n",
        "  test_attention_masks_whereoperator_tpu = test_attention_masks_whereoperator\n",
        "  test_segment_ids_whereoperator = test_segment_ids\n",
        "  test_segment_ids_whereoperator = torch.tensor(test_segment_ids_whereoperator)\n",
        "  test_segment_ids_whereoperator_tpu = test_segment_ids_whereoperator\n",
        "  whereoperator_model.eval()\n",
        "  with torch.no_grad():\n",
        "    logits = whereoperator_model(input_ids=test_input_ids_whereoperator_tpu, token_type_ids=test_segment_ids_whereoperator_tpu, attention_mask=test_attention_masks_whereoperator_tpu)\n",
        "  logits = logits.detach().cpu().numpy()\n",
        "  sigmoid_logits = [1/(1+np.exp(-1 * each_logit)) for each_logit in logits]\n",
        "  max_index = np.argmax(sigmoid_logits, axis=1)\n",
        "  return max_index, sigmoid_logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kmr-WLT0OAwY",
        "colab_type": "text"
      },
      "source": [
        "Predict Where Value"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cc5vLrJ_E9fh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def prediction_where_value(wherevalue_model, test_input_ids, test_attention_masks, test_segment_ids):\n",
        "  # wherevalue_model.to(test_device)\n",
        "  test_input_ids_whereoperator = test_input_ids\n",
        "  test_input_ids_whereoperator = torch.tensor(test_input_ids_whereoperator)\n",
        "  test_input_ids_whereoperator_tpu = test_input_ids_whereoperator\n",
        "  test_attention_masks_whereoperator = test_attention_masks\n",
        "  test_attention_masks_whereoperator = torch.tensor(test_attention_masks_whereoperator)\n",
        "  test_attention_masks_whereoperator_tpu = test_attention_masks_whereoperator\n",
        "  test_segment_ids_whereoperator = test_segment_ids\n",
        "  test_segment_ids_whereoperator = torch.tensor(test_segment_ids_whereoperator)\n",
        "  test_segment_ids_whereoperator_tpu = test_segment_ids_whereoperator\n",
        "  wherevalue_model.eval()\n",
        "  with torch.no_grad():\n",
        "    start_logits, end_logits = wherevalue_model(input_ids=test_input_ids_whereoperator_tpu, token_type_ids=test_segment_ids_whereoperator_tpu, attention_mask=test_attention_masks_whereoperator_tpu)\n",
        "  start_logits = start_logits.detach().cpu().numpy()\n",
        "  end_logits = end_logits.detach().cpu().numpy()\n",
        "  sigmoid_start_logits = [1/(1+np.exp(-1 * each_logit)) for each_logit in start_logits]\n",
        "  sigmoid_end_logits = [1/(1+np.exp(-1 * each_logit)) for each_logit in end_logits]\n",
        "  start_index = np.argmax(sigmoid_start_logits, axis=1)\n",
        "  end_index = np.argmax(sigmoid_end_logits, axis=1)\n",
        "  return start_index, end_index, sigmoid_start_logits, sigmoid_end_logits"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdaTTLZM1r3J",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def final_function(input_question, input_columns, input_types, max_len, tokenizer, aggregation_operator_list, condition_operator_list, table_name, selection_model, aggregation_model, wherenum_model, isinrelevance_model, isinwhere_model, whereoperator_model, wherevalue_model):\n",
        "  current_test_tokenized, current_test_input_ids, current_test_attention_masks, current_test_segment_ids = prepare_input(question=input_question, columns=input_columns, types=input_types, max_len=max_len, bert_tokenizer=tokenizer)\n",
        "  selection_index, selection_sigmoid = prediction_selection_clause(selection_model=selection_model, test_input_ids=current_test_input_ids, test_attention_masks=current_test_attention_masks, test_segment_ids=current_test_segment_ids)\n",
        "  aggregation_index, aggregation_sigmoid = prediction_aggregation_operator(aggregation_model=aggregation_model, test_input_ids=current_test_input_ids[selection_index], test_attention_masks=current_test_attention_masks[selection_index], test_segment_ids=current_test_segment_ids[selection_index])\n",
        "  wherenum_probability = prediction_wherenum(wherenum_model=wherenum_model, test_input_ids=current_test_input_ids, test_attention_masks=current_test_attention_masks, test_segment_ids=current_test_segment_ids)\n",
        "  isinrelevance_probability = prediction_isinrelevance(isinrelevance_model=isinrelevance_model, test_input_ids=current_test_input_ids, test_attention_masks=current_test_attention_masks, test_segment_ids=current_test_segment_ids)\n",
        "  wherenum_prediction = np.argmax(np.matmul(np.transpose(wherenum_probability), np.array(isinrelevance_probability)))\n",
        "  isinwhere_probability = prediction_isinwhere(isinwhere_model=isinwhere_model, test_input_ids=current_test_input_ids, test_attention_masks=current_test_attention_masks, test_segment_ids=current_test_segment_ids)\n",
        "  where_columns = prediction_wherecolumns(isinwhere_probability, wherenum_prediction)\n",
        "  whereoperator_index, whereoperator_sigmoid = prediction_where_operator(whereoperator_model=whereoperator_model, test_input_ids=[current_test_input_ids[index] for index in where_columns], test_attention_masks=[current_test_attention_masks[index] for index in where_columns], test_segment_ids=[current_test_segment_ids[index] for index in where_columns])\n",
        "  start_index, end_index, start_probability, end_probability = prediction_where_value(wherevalue_model=wherevalue_model, test_input_ids=[current_test_input_ids[index] for index in where_columns], test_attention_masks=[current_test_attention_masks[index] for index in where_columns], test_segment_ids=[current_test_segment_ids[index] for index in where_columns])\n",
        "  # get actual where value\n",
        "  where_value_list = []\n",
        "  if len(where_columns) > 0:\n",
        "    for i in range(len(where_columns)):\n",
        "      current_tokens = current_test_tokenized[where_columns[i]]\n",
        "      current_start_index = start_index[i]\n",
        "      current_end_index = end_index[i]\n",
        "      # need to take care of current_star_index == current_end_index == 0\n",
        "      if current_start_index == 0 and current_end_index == 0:\n",
        "        # get second largest from start_probability and end_probability\n",
        "        second_start_probability = np.partition(start_probability[i].flatten(), -2)[-2]\n",
        "        second_end_probability = np.partition(end_probability[i].flatten(), -2)[-2]\n",
        "        first_start_probability = start_probability[i][current_start_index]\n",
        "        first_end_probability = end_probability[i][current_end_index]\n",
        "        # apply a threshold\n",
        "        if (first_end_probability / second_end_probability < 10) and (first_start_probability / second_start_probability < 10):\n",
        "          current_start_index = list(start_probability[i]).index(second_start_probability)\n",
        "          current_end_index = list(end_probability[i]).index(second_end_probability)\n",
        "      value_span = current_tokens[current_start_index: current_end_index+1]\n",
        "      predicted_answer = ''\n",
        "      for i, each_token in enumerate(value_span):\n",
        "        if i == 0:\n",
        "          if len(each_token) > 2:\n",
        "            if each_token[0:2] == '##':\n",
        "              predicted_answer = predicted_answer + each_token[2:]\n",
        "            else:\n",
        "              predicted_answer = predicted_answer + each_token\n",
        "          else:\n",
        "            predicted_answer = predicted_answer + each_token\n",
        "        else:\n",
        "          if len(each_token) <= 2:\n",
        "            predicted_answer = predicted_answer + ' ' + each_token\n",
        "          elif each_token[0:2] == '##':\n",
        "            predicted_answer = predicted_answer + each_token[2:]\n",
        "          else:\n",
        "            predicted_answer = predicted_answer + ' ' + each_token\n",
        "      where_value_list.append(predicted_answer)\n",
        "  final_selection_column = input_columns[selection_index]\n",
        "  final_aggregation_operator = aggregation_operator_list[aggregation_index]\n",
        "  final_where_clauses = []\n",
        "  if len(where_columns) > 0:\n",
        "    for i in range(len(where_columns)):\n",
        "      current_where_clause = ''\n",
        "      current_where_clause = current_where_clause + input_columns[where_columns[i]] + ' ' + condition_operator_list[whereoperator_index[i]] + ' ' + where_value_list[i]\n",
        "      final_where_clauses.append(current_where_clause)\n",
        "  final_query = 'SELECT '\n",
        "  if final_aggregation_operator == 'NAN' and input_types[selection_index] == 'real':\n",
        "    final_query = final_query + final_selection_column + ' '\n",
        "  elif final_aggregation_operator == 'NAN' and input_types[selection_index] == 'text':\n",
        "    final_query = final_query + 'DISTINCT ' + '(' + final_selection_column + ') '\n",
        "  else:\n",
        "    final_query = final_query + final_aggregation_operator + '(' + final_selection_column + ') '\n",
        "  final_query = final_query + 'FROM ' + table_name\n",
        "  if len(final_where_clauses) > 0:\n",
        "    final_query = final_query + ' WHERE'\n",
        "    for j in range(len(final_where_clauses)):\n",
        "      if where_value_list[j] != '[CLS]':\n",
        "        final_query = final_query + ' ' + final_where_clauses[j] + ' AND'\n",
        "  final_query = final_query[:-4]\n",
        "  return final_query\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "piR-_UEuM-YH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Input questions and table headers as well as table type\n",
        "input_question = 'Who should I find, if I want to buy fruits in America? Or If I want to buy fruits in America, who should I find? '\n",
        "input_columns = ['Region', 'Fruit', 'Amount (kilo) weight', 'Salesperson', 'Customer Type', 'Revenue (dollar)', 'Profit (dollar)']\n",
        "input_types = ['text', 'text', 'real', 'text', 'text', 'real', 'real']\n",
        "MAX_LEN = 64\n",
        "tokenizer = BertTokenizer.from_pretrained('bert-large-uncased', do_lower_case=True)\n",
        "aggregation_operator_list = [\"NAN\", \"max\", \"min\", \"count distinct\", \"sum\", \"mean\"]\n",
        "condition_operator_list = [\"=\", \">\", \"<\"]\n",
        "table_name = 'Fruits'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F1f-kh8tPSKc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_result= final_function(input_question, input_columns, input_types, MAX_LEN, tokenizer, aggregation_operator_list, condition_operator_list, table_name, selection_model, aggregation_model, wherenum_model, isinrelevance_model, isinwhere_model, whereoperator_model, wherevalue_model)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}